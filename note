autoscaling set to zero for night shut down otherwise kubernetes will schedule pods/nodes
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name eks-gpu-e2e-cluster-gpu-on-demand-28cd5e84-2e03-7518-7c2f-af05374b5eec \
  --desired-capacity 0

This cleanly drains all GPU nodes.

Tomorrow, scale back up (desired-capacity 1) â†’ new nodes come online, plugin redeploys, Triton reschedules.

Persistent model repo must be PVC/S3, otherwise models are lost.
==============

You need to update the ASG min size first, then scale down:

bash
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name eks-gpu-e2e-cluster-gpu-on-demand-28cd5e84-2e03-7518-7c2f-af05374b5eec \
  --min-size 0 \
  --desired-capacity 0
==================


aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name eks-gpu-e2e-cluster-gpu-on-demand-28cd5e84-2e03-7518-7c2f-af05374b5eec \
  --min-size 0 \
  --max-size 0 \
  --desired-capacity 0

Tommorow Plan : 
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name eks-gpu-e2e-cluster-gpu-on-demand-28cd5e84-2e03-7518-7c2f-af05374b5eec \
  --min-size 1 \
  --desired-capacity 1


=========================================================================
# Nodegroup cluster information : 

# cluster-name =  gpu-e2e-cluster 
# nodegroup-name =  gpu-e2e-cluster-gpu-on-demand
# nodeRole = arn:aws:iam::478253497479:role/gpu-e2e-cluster-node-role
#========================================================================

EC2-dev-->aws eks describe-nodegroup \
  --cluster-name gpu-e2e-cluster \
  --nodegroup-name gpu-e2e-cluster-gpu-on-demand
{
    "nodegroup": {
        "nodegroupName": "gpu-e2e-cluster-gpu-on-demand",
        "nodegroupArn": "arn:aws:eks:us-east-1:478253497479:nodegroup/gpu-e2e-cluster/gpu-e2e-cluster-gpu-on-demand/28cd5e84-2e03-7518-7c2f-af05374b5eec",
        "clusterName": "gpu-e2e-cluster",
        "version": "1.34",
        "releaseVersion": "1.34.2-20251120",
        "createdAt": "2025-11-25T22:00:33.992000+00:00",
        "modifiedAt": "2025-11-26T15:51:32.619000+00:00",
        "status": "ACTIVE",
        "capacityType": "ON_DEMAND",
        "scalingConfig": {
            "minSize": 0,
            "maxSize": 2,
            "desiredSize": 0
        },
        "instanceTypes": [
            "g4dn.xlarge"
        ],
        "subnets": [
            "subnet-051d69cff74f62c2d"
        ],
        "amiType": "AL2023_x86_64_NVIDIA",
        "nodeRole": "arn:aws:iam::478253497479:role/gpu-e2e-cluster-node-role",
        "labels": {
            "accelerator": "nvidia"
        },
        "resources": {
            "autoScalingGroups": [
                {
                    "name": "eks-gpu-e2e-cluster-gpu-on-demand-28cd5e84-2e03-7518-7c2f-af05374b5eec"
                }
            ]
        },
        "diskSize": 20,
        "health": {
            "issues": []
        },
        "updateConfig": {
            "maxUnavailable": 1
        },
        "tags": {
            "owner": "Nancy",
            "project": "gpu-e2e"
        }
    }










